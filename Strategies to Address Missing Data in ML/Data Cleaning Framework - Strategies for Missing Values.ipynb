{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6760f8e-5c50-41de-a14d-45960e6b0e50",
   "metadata": {},
   "source": [
    "Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b180ef6-526e-4bfd-8350-dfd4934d7b90",
   "metadata": {},
   "source": [
    "In the field of data science, effective data cleaning is crucial for ensuring the accuracy and reliability of analysis and machine learning models. One of the most prevalent issues in datasets is the presence of missing values, which can arise from various factors such as incomplete data collection, human error, or technical malfunctions. Addressing missing data is essential, as neglecting to do so can lead to skewed results and compromised model performance.\n",
    "\n",
    "This notebook presents a systematic approach to handling missing values, showcasing various methodologies employed in data cleaning. The following techniques will be explored:\n",
    "1. Deletion Methods: Techniques such as listwise deletion and pairwise deletion, which involve removing records with missing values.\n",
    "2. Imputation Techniques:\n",
    "\n",
    "   2.1 Mean/Median/Mode Imputation: Replacing missing values with the mean, median, or mode of the respective feature.\n",
    "\n",
    "   2.2 K-Nearest Neighbors (KNN) Imputation: Using the values from the nearest neighbors to fill in missing data.\n",
    "\n",
    "   2.3 Regression Imputation: Predicting missing values based on relationships with other features in the dataset.\n",
    "    \n",
    "   2.4 Random Forest Imputation: Leveraging the power of ensemble learning to predict and replace missing values\n",
    "\n",
    "3. Advanced Techniques: Multivariate Imputation by Chained Equations (MICE): A sophisticated approach that uses multiple regression models to predict missing values iteratively.\n",
    "\n",
    "By employing these methodologies, this notebook aims to provide a comprehensive understanding of how to effectively handle missing values, thereby enhancing data quality and integrity. Ultimately, the techniques presented here will empower data practitioners to make informed decisions, leading to improved analytical outcomes and model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa8787c-474a-43ae-9b66-d63eb950d116",
   "metadata": {},
   "source": [
    "Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c70cd01-3516-4e07-a224-db2da424d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer,KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480f1401-1cfa-4891-b49c-120341e02289",
   "metadata": {},
   "source": [
    "Load the Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1e9a40-b5cc-40fd-80f2-2d8341cf7200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset('titanic')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb22bc74-f1b8-4971-a2da-cea2d24910ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4587d61-803e-491e-ac04-11ea7a5b24d2",
   "metadata": {},
   "source": [
    "check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92eb6082-f741-4271-9add-b7365a10f38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73110f-1e53-4dea-951a-2fca011a56e6",
   "metadata": {},
   "source": [
    "Deletion Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd26a80-f998-4bf3-806f-1fb3804a3552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of Original DataFrame: (891, 15)\n",
      "Shape after Listwise Deletion: (182, 15)\n"
     ]
    }
   ],
   "source": [
    "# Listwise deletion (dropping rows with any missing values)\n",
    "\n",
    "df_listwise = df.dropna()\n",
    "\n",
    "# Display the shape of the original and the modified DataFrame\n",
    "\n",
    "print(\"\\nShape of Original DataFrame:\", df.shape)\n",
    "print(\"Shape after Listwise Deletion:\", df_listwise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ab05eb-1967-4e39-ab24-feb5ba617ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation Matrix (using Pairwise Deletion):\n",
      "           survived    pclass       age     sibsp     parch      fare\n",
      "survived  1.000000 -0.338481 -0.077221 -0.035322  0.081629  0.257307\n",
      "pclass   -0.338481  1.000000 -0.369226  0.083081  0.018443 -0.549500\n",
      "age      -0.077221 -0.369226  1.000000 -0.308247 -0.189119  0.096067\n",
      "sibsp    -0.035322  0.083081 -0.308247  1.000000  0.414838  0.159651\n",
      "parch     0.081629  0.018443 -0.189119  0.414838  1.000000  0.216225\n",
      "fare      0.257307 -0.549500  0.096067  0.159651  0.216225  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Pairwise deletion example\n",
    "# For demonstration, we'll calculate the correlation matrix using pairwise deletion\n",
    "# Select only numeric columns for correlation\n",
    "\n",
    "numeric_df = df.select_dtypes(include=['number'])  # Select only numeric columns\n",
    "correlation_matrix = numeric_df.corr(method='pearson')  # Automatically handles missing values\n",
    "print(\"\\nCorrelation Matrix (using Pairwise Deletion):\\n\", correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987da5a2-b3f8-4540-9bf6-29b743ae4891",
   "metadata": {},
   "source": [
    "Imputation Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a01d46-2572-47e1-9663-795a84544d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values before Mean Imputation: 203\n",
      "Mean Imputation for 'fare' Value = 32.18247848837209\n",
      "Number of missing values after Mean Imputation: 0\n",
      "********************************************************************************\n",
      "Number of missing values before Median Imputation: 203\n",
      "Median Imputation for 'fare' Value = 14.45625\n",
      "Number of missing values after Median Imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Mean/Median/Mode Imputation\n",
    "# for Continuous Data Handling use Mean/Median\n",
    "# frist add null in Continuous Feature\n",
    "\n",
    "np.random.seed(42)\n",
    "missing_mask = np.random.rand(df.shape[0]) < 0.2\n",
    "df.loc[missing_mask, 'fare'] = np.nan\n",
    "\n",
    "# 1.1 Mean Imputation for 'fare'\n",
    "\n",
    "df2 = df.copy()\n",
    "mean_fare = df2['fare'].mean()\n",
    "print(\"Number of missing values before Mean Imputation:\", df2['fare'].isnull().sum())\n",
    "df2['fare'].fillna(mean_fare, inplace=True)\n",
    "print(f\"Mean Imputation for 'fare' Value = {mean_fare}\")\n",
    "print(\"Number of missing values after Mean Imputation:\", df2['fare'].isnull().sum())\n",
    "\n",
    "print(\"*\"*80)\n",
    "\n",
    "# 1.2 Median Imputation for 'fare'\n",
    "\n",
    "df2 = df.copy()\n",
    "print(\"Number of missing values before Median Imputation:\", df2['fare'].isnull().sum())\n",
    "median_fare = df2['fare'].median()\n",
    "df2['fare'].fillna(median_fare, inplace=True)\n",
    "print(f\"Median Imputation for 'fare' Value = {median_fare}\")\n",
    "print(\"Number of missing values after Median Imputation:\", df2['fare'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36684432-346d-4ce9-b11a-ef1c910eedaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values before Mean Imputation: 203\n",
      "Mean Imputation for 'fare' Value = 32.18247848837209\n",
      "Number of missing values after Mean Imputation: 0\n",
      "********************************************************************************\n",
      "Number of missing values before Median Imputation: 203\n",
      "Median Imputation for 'fare' Value = 14.45625\n",
      "Number of missing values after Median Imputation: 0\n"
     ]
    }
   ],
   "source": [
    "### another way using Sklearn\n",
    "# 1.1 Mean Imputation for 'fare'\n",
    "\n",
    "df2 = df.copy()\n",
    "print(\"Number of missing values before Mean Imputation:\", df2['fare'].isnull().sum())\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "df2['fare'] = mean_imputer.fit_transform(df2[['fare']])\n",
    "print(f\"Mean Imputation for 'fare' Value = {mean_imputer.statistics_[0]}\")\n",
    "print(\"Number of missing values after Mean Imputation:\", df2['fare'].isnull().sum())\n",
    "\n",
    "print(\"*\"*80)\n",
    "\n",
    "# 1.2 Median Imputation for 'fare'\n",
    "\n",
    "df2 = df.copy()\n",
    "print(\"Number of missing values before Median Imputation:\", df2['fare'].isnull().sum())\n",
    "med_imputer = SimpleImputer(strategy='median')\n",
    "df2['fare'] = med_imputer.fit_transform(df2[['fare']])\n",
    "print(f\"Median Imputation for 'fare' Value = {med_imputer.statistics_[0]}\")\n",
    "print(\"Number of missing values after Median Imputation:\", df2['fare'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b38b3b8e-1543-43ed-9e4a-369803f10096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values before Mode Imputation for 'deck': 688\n",
      "Mode Imputation for 'deck' Value = C\n",
      "Number of missing values after Mode Imputation for 'deck': 0\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Mean/Median/Mode Imputation\n",
    "# for Discrete Data Handling use mod/Median (for numerical not Categorical )\n",
    "\n",
    "df2 = df.copy()\n",
    "\n",
    "# 1.1 Mode Imputation for 'deck'\n",
    "\n",
    "print(\"Number of missing values before Mode Imputation for 'deck':\", df2['deck'].isnull().sum())\n",
    "mode_deck = df2['deck'].mode()[0]\n",
    "df2['deck'].fillna(mode_deck, inplace=True)\n",
    "print(f\"Mode Imputation for 'deck' Value = {mode_deck}\")\n",
    "print(\"Number of missing values after Mode Imputation for 'deck':\", df2['deck'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc0d69ed-c334-4de0-9985-0b92c074cb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values before Mode Imputation for 'deck': 688\n",
      "Mode Imputation for 'embarked' Value = C\n",
      "Number of missing values after Mode Imputation for 'deck': 0\n"
     ]
    }
   ],
   "source": [
    "### another way using Sklearn\n",
    "\n",
    "df2 = df.copy()\n",
    "print(\"Number of missing values before Mode Imputation for 'deck':\", df2['deck'].isnull().sum())\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df2['deck'] = mode_imputer.fit_transform(df2[['deck']]).flatten() \n",
    "print(f\"Mode Imputation for 'embarked' Value = {mode_imputer.statistics_[0]}\")\n",
    "print(\"Number of missing values after Mode Imputation for 'deck':\", df2['deck'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f9d3d94-a13c-4a75-8265-99ae177039b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values before Imputation for 'fare': 203\n",
      "Missing Values after Imputation for 'fare': 0\n"
     ]
    }
   ],
   "source": [
    "# 2.2 K-Nearest Neighbors (KNN) Imputation for Continuous KNN is not applicable to non-numeric data.\n",
    "\n",
    "df2 = df.copy()\n",
    "print(\"Missing Values before Imputation for 'fare':\", df2['fare'].isnull().sum())\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df2[['fare']] = imputer.fit_transform(df2[['fare']])\n",
    "print(\"Missing Values after Imputation for 'fare':\", df2['fare'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b8fd6-8d9e-4b3f-aa32-b82c3063ee80",
   "metadata": {},
   "source": [
    "Machine Learning-Based Imputation for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0efd25ae-8acc-40c9-bbb2-73dce4e27c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 'fare' values for missing data:\n",
      "[ 8.79768036  8.79768036 37.40036826 15.5281786   8.79768036 13.99126981\n",
      " 13.99126981  8.79768036  8.79768036 79.03317472]\n",
      "Missing Values After ML Imputation in 'fare': 0\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Regression Imputation for Continuous use any model to predict null values\n",
    "\n",
    "df2 = df.copy()\n",
    "missing_mask = df2['fare'].isnull()\n",
    "\n",
    "# Prepare features and target variable for training the model\n",
    "# Assuming 'age', 'pclass', and 'sibsp' are useful features to predict 'fare'\n",
    "\n",
    "features = ['parch', 'pclass', 'sibsp','survived']\n",
    "df2_non_missing = df2.loc[~missing_mask, features + ['fare']].dropna()\n",
    "X = df2_non_missing[features]\n",
    "y = df2_non_missing['fare']\n",
    "\n",
    "# Train the RandomForestRegressor model\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Predict missing values in 'fare'\n",
    "\n",
    "X_missing = df2.loc[missing_mask, features]\n",
    "predicted_fare = rf.predict(X_missing)\n",
    "\n",
    "# Fill the missing values in 'fare' column with the predicted values\n",
    "\n",
    "df2.loc[missing_mask, 'fare'] = predicted_fare\n",
    "\n",
    "# Print the imputed values for verification\n",
    "\n",
    "print(\"Predicted 'fare' values for missing data:\")\n",
    "print(predicted_fare[:10])\n",
    "\n",
    "# Verify if missing values are filled\n",
    "\n",
    "print(\"Missing Values After ML Imputation in 'fare':\", df2['fare'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37c46172-ae4f-4ffe-86c6-c154b7d1e300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 'deck' values for missing data:\n",
      "['F', 'E', 'F', 'F', 'G', 'G', 'F', 'F', 'G', 'F']\n",
      "Categories (7, object): ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
      "Missing Values After ML Imputation in 'deck': 0\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Random Forest Imputation for Discrete use any model to predict null values\n",
    "\n",
    "df2 = df.copy()\n",
    "missing_mask = df2['deck'].isnull()\n",
    "\n",
    "# Prepare features and target variable for training the model\n",
    "# Assuming 'age', 'pclass', and 'sibsp' are useful features to predict 'fare'\n",
    "\n",
    "features = ['parch', 'pclass', 'sibsp','survived']\n",
    "df2_non_missing = df2.loc[~missing_mask, features + ['deck']].dropna()\n",
    "X = df2_non_missing[features]\n",
    "y = df2_non_missing['deck'].astype('category').cat.codes\n",
    "\n",
    "# Train the RandomForestClassifier model\n",
    "\n",
    "rf_classifier  = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier .fit(X, y)\n",
    "\n",
    "# Predict missing values in 'deck'\n",
    "\n",
    "X_missing = df2.loc[missing_mask, features]\n",
    "predicted_deck = rf_classifier .predict(X_missing)\n",
    "\n",
    "# Fill the missing values in 'deck' column with the predicted values\n",
    "\n",
    "df2.loc[missing_mask, 'deck'] = pd.Categorical.from_codes(predicted_deck, df2_non_missing['deck'].astype('category').cat.categories)\n",
    "\n",
    "# Print the imputed values for verification\n",
    "\n",
    "print(\"Predicted 'deck' values for missing data:\")\n",
    "print(df2.loc[missing_mask, 'deck'][:10].values)\n",
    "\n",
    "# Verify if missing values are filled\n",
    "\n",
    "print(\"Missing Values After ML Imputation in 'deck':\", df2['deck'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe721dc8-4e56-4d34-b543-0f8fffa3e6b1",
   "metadata": {},
   "source": [
    "Advanced Techniques: Multivariate Imputation by Chained Equations (MICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c32bfbf3-1603-4be7-a8a7-6af687d230af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 'fare' values for missing data:\n",
      "[32.18247849 32.18247849 32.18247849 32.18247849 32.18247849 32.18247849\n",
      " 32.18247849 32.18247849 32.18247849 32.18247849]\n",
      "Missing Values After IterativeImputer in 'fare': 0\n"
     ]
    }
   ],
   "source": [
    "# Define the IterativeImputer with different models for continuous variables\n",
    "\n",
    "df2 = df.copy()\n",
    "missing_mask = df2['fare'].isnull()\n",
    "imputer = IterativeImputer(\n",
    "    estimator=RandomForestRegressor(n_estimators=100, random_state=42), \n",
    "    max_iter=100, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform imputation on the continuous variables\n",
    "\n",
    "df2['fare'] = imputer.fit_transform(df[['fare']])\n",
    "print(\"Predicted 'fare' values for missing data:\")\n",
    "print(df2.loc[missing_mask, 'fare'][:10].values)\n",
    "\n",
    "print(\"Missing Values After IterativeImputer in 'fare':\", df2['fare'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98b3f0f0-680f-415b-8fe3-5a92db13053a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
      "Categories (7, object): ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
      "Missing Values After IterativeImputer in 'deck': 0\n"
     ]
    }
   ],
   "source": [
    "# Define the IterativeImputer with different models for Discrete variables\n",
    "\n",
    "df2 = df.copy()\n",
    "missing_mask = df2['deck'].isnull()\n",
    "df2.deck = df2.deck.astype('category').cat.codes\n",
    "df2.deck.replace(-1,np.NAN,inplace=True)\n",
    "\n",
    "imputer = IterativeImputer(\n",
    "    estimator=RandomForestClassifier(n_estimators=100, random_state=42), \n",
    "    max_iter=100, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform imputation on the continuous variables\n",
    "\n",
    "df2['deck'] = imputer.fit_transform(df2[['deck']])\n",
    "\n",
    "# Convert the imputed 'deck' column back to categorical after imputation\n",
    "\n",
    "df2['deck'] = pd.Categorical.from_codes(\n",
    "    df2['deck'].round(0).astype(int), \n",
    "    df['deck'].astype('category').cat.categories\n",
    ")\n",
    "print(df2.loc[missing_mask,'deck'][:10].values)\n",
    "print(\"Missing Values After IterativeImputer in 'deck':\", df2['deck'].isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
